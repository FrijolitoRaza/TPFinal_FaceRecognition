{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLVXlB5GaJVv"
      },
      "source": [
        "# Sistema de asistencia basado en el reconocimiento facial\n",
        "\n",
        "## Introducción\n",
        "\n",
        "Este proyecto muestra un Sistema de asistencia basado en el reconocimiento facial desarrollado en Python. Los sistemas tradicionales de control de asistencia suelen ser manuales, propensos a errores y lentos. Aprovechando el reconocimiento facial, podemos automatizar el proceso, creando una solución más eficiente, precisa y rentable. Esto es especialmente beneficioso para instituciones como escuelas y empresas, donde el control de asistencia de un gran número de personas es una tarea diaria. La automatización elimina los errores humanos, evita las entradas fraudulentas (como la asistencia por poder) y libera un tiempo valioso para actividades más productivas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFK-FPCNaJVx"
      },
      "source": [
        "## Antecedentes y motivación\n",
        "\n",
        "Los sistemas manuales de control de asistencia adolecen de varios inconvenientes, como la posibilidad de cometer errores, el posible robo de tiempo o falsificación de registros asistenciales, y la carga administrativa que supone compilar manualmente los registros. Grandes empresas tecnológicas como Amazon, Microsoft y Face++ ya han demostrado el poder del reconocimiento facial para la seguridad, el control de acceso y la identificación de usuarios.\n",
        "\n",
        "La motivación de este proyecto es aplicar conceptos fundamentales de la visión por ordenador y el aprendizaje automático para crear una aplicación práctica en el mundo real. El objetivo es crear un prototipo accesible y de bajo coste que pueda implementarse utilizando una cámara web estándar y bibliotecas Python de código abierto, convirtiéndolo en una opción viable para organizaciones con presupuestos limitados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajGf4NaRaJVx"
      },
      "source": [
        "## Desarrollo del proyecto\n",
        "\n",
        "### Herramientas utilizadas\n",
        "\n",
        "* Lenguaje de programación:Python\n",
        "* **Bibliotecas:**\n",
        "    * `NumPy`: Para operaciones numéricas y manejo de datos de imagen como matrices.\n",
        "    * `OpenCV`: Para procesamiento y manejo de imágenes.\n",
        "    * `face_recognition`: Una librería sencilla y potente para detectar, reconocer y manipular caras.\n",
        "    * `cmake`: Herramienta que configura y gestiona la compilación de bibliotecas como `dlib`.\n",
        "    * `dlib`: Biblioteca que proporciona algoritmos para la deteción y codificación de rostros, fundamentales para el reconocimiento facial.\n",
        "* **Hardware:** Ordenador portátil o de sobremesa con webcam (para captura de imágenes).\n",
        "* **Entorno de desarrollo:** Cursor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fePhv3JaJVx"
      },
      "source": [
        "### Paso 1: Instalar e importar las librerías necesarias\n",
        "\n",
        "En primer lugar, tenemos que instalar las bibliotecas necesarias. `dlib` es un prerrequisito para `face_recognition`. También instalaremos `cmake` para asegurarnos de que `dlib` compila correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adicionalmente, en caso de errores al tratar de instalar CMake, descargalo desde su sitio web oficial: https://cmake.org/download/. Abrí el instalador, marcá la opción \"Add CMake to system PATH for all users\", instalá, reiniciá la terminal y corré esta línea de código:\n",
        "\n",
        "\n",
        "`cmake --version`\n",
        "\n",
        "Deberías recibir un mensaje con la versión instalada de dicho sistema.\n",
        "\n",
        "Por otro lado, en caso de tener errores en la instalación de dlib, descargá Visual Studio 2022, en su versión Community, desde https://visualstudio.microsoft.com/es/downloads/. Luego, en el instalador, seleccioná \"Desarrollo para el escritorio con C++\" y continuá con la instalación. Finalmente, reiniciá la terminal e intentá instalar las dependencias nuevamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbhuJlR9aJVy",
        "outputId": "09793432-b593-4fee-fa3d-7b319044f32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HINT: You are attempting to install a package literally named \"requirements.txt\" (which cannot exist). Consider using the '-r' flag to install the packages listed in requirements.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement requirements.txt (from versions: none)\n",
            "ERROR: No matching distribution found for requirements.txt\n"
          ]
        }
      ],
      "source": [
        "!pip install requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVQjf4MAaJVy"
      },
      "source": [
        "Ahora, vamos a importar las bibliotecas que vamos a utilizar en todo el proyecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF-WBzSgaJVz"
      },
      "source": [
        "### Paso 2: Cargar imágenes de personas conocidas\n",
        "\n",
        "Necesitamos una base de datos de caras conocidas con las que comparar. Para este notebook, crearemos un directorio llamado `known_faces` y cargaremos imágenes en él. Cada archivo de imagen debe llevar el nombre de la persona que aparece en la foto (por ejemplo, `elon_musk.jpg`, `bill_gates.png`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Verificando la configuración inicial ---\n",
            "Directorio 'IMG' encontrado. El programa continuará.\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 2: VERIFICAR Y/O CREAR EL DIRECTORIO DE IMÁGENES ---\n",
        "\n",
        "# Nombre del directorio para las imágenes de rostros conocidos.\n",
        "# Lo definimos en una variable para usarlo fácilmente en todo el script.\n",
        "image_directory = \"IMG\"\n",
        "\n",
        "print(\"--- Verificando la configuración inicial ---\")\n",
        "\n",
        "# Comprobar si el directorio de imágenes no existe.\n",
        "if not os.path.exists(image_directory):\n",
        "    # Si no existe, notificar al usuario.\n",
        "    print(f\"El directorio '{image_directory}' no fue encontrado.\")\n",
        "    \n",
        "    # Crear el directorio.\n",
        "    os.makedirs(image_directory)\n",
        "    print(f\"Se ha creado el directorio '{image_directory}'.\")\n",
        "    \n",
        "    # Dar la instrucción clave y detener el script para que el usuario pueda actuar.\n",
        "    print(\"\\n*** ACCIÓN REQUERIDA ***\")\n",
        "    print(f\"Por favor, añade las imágenes de los rostros conocidos (.jpg, .png) en la carpeta '{image_directory}' y vuelve a ejecutar el script.\")\n",
        "    \n",
        "    # Detenemos la ejecución. Sin imágenes, el resto del programa no puede funcionar.\n",
        "    exit()\n",
        "else:\n",
        "    # Si el directorio ya existe, notificar que todo está en orden.\n",
        "    print(f\"Directorio '{image_directory}' encontrado. El programa continuará.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0etenkzaJVz"
      },
      "source": [
        "### Paso 3: Codificar 'Known Faces'\n",
        "\n",
        "El núcleo del reconocimiento facial es convertir una cara en una representación matemática, llamada «codificación». Se trata de un vector de 128 números que es único para cada cara. Ahora procesaremos cada imagen cargada, detectaremos la cara y generaremos su codificación. Almacenaremos estas codificaciones junto con el nombre de la persona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando rostros conocidos...\n",
            "Se procesaron 6 rostros conocidos.\n",
            "Nombres conocidos: ['Adrian_DIAZ', 'Ana_DEARMAS', 'Daiana_FRETE', 'Hanna_DIAZ', 'Michael_MANDO', 'Nataly_PEREZ']\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 3: CODIFICAR LOS ROSTROS CONOCIDOS ---\n",
        "# \n",
        "# # Listas para almacenar las codificaciones de los rostros conocidos y sus nombres.\n",
        "known_face_encodings = []\n",
        "known_face_names = []\n",
        "\n",
        "print(\"Procesando rostros conocidos...\")\n",
        "\n",
        "# Recorrer cada archivo en el directorio de rostros conocidos.\n",
        "for filename in os.listdir(image_directory):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        # Cargar el archivo de imagen.\n",
        "        image_path = os.path.join(image_directory, filename)\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "\n",
        "        # Obtener la codificación del rostro (se asume una cara por imagen).\n",
        "        face_encodings = face_recognition.face_encodings(image)\n",
        "\n",
        "        if face_encodings:\n",
        "            encoding = face_encodings[0]\n",
        "            # Agregar la codificación y el nombre (sin la extensión del archivo) a las listas.\n",
        "            known_face_encodings.append(encoding)\n",
        "            known_face_names.append(os.path.splitext(filename)[0])\n",
        "\n",
        "print(f\"Se procesaron {len(known_face_names)} rostros conocidos.\")\n",
        "print(\"Nombres conocidos:\", known_face_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PASO 4: REGISTRAR LOS ROSTROS CONOCIDOS COMO ASISTENCIAS\n",
        "\n",
        "\n",
        "Se registra la asistencia de una persona en el archivo `attendance.csv`, guardando su nombre y la hora exacta en que fue detectada. Antes de agregar una nueva entrada, verifica si esa persona ya fue registrada en la sesión actual, evitando duplicados. Usa el modo de archivo 'a+' para permitir lectura y escritura, y para crear el archivo si no existe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- PASO 4: FUNCIÓN PARA MARCAR LA ASISTENCIA ---\n",
        "\n",
        "def mark_attendance(name):\n",
        "    \"\"\"\n",
        "    Registra el nombre y la hora en el archivo attendance.csv.\n",
        "    Evita registrar a la misma persona más de una vez por sesión.\n",
        "    \"\"\"\n",
        "    # Usar 'a+' para abrir el archivo en modo de anexo (lo crea si no existe).\n",
        "    with open('attendance.csv', 'a+') as f:\n",
        "        # Mover el cursor al inicio para leer las entradas existentes.\n",
        "        f.seek(0)\n",
        "        my_data_list = f.readlines()\n",
        "        name_list = []\n",
        "        for line in my_data_list:\n",
        "            entry = line.split(',')\n",
        "            name_list.append(entry[0])\n",
        "\n",
        "        # Comprobar si el nombre no ha sido ya registrado.\n",
        "        if name not in name_list:\n",
        "            now = datetime.now()\n",
        "            dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "            f.writelines(f'\\n{name},{dt_string}')\n",
        "            print(f\"Asistencia marcada para {name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNKiyM5UaJV0"
      },
      "source": [
        "### Paso 5: Capturar una Imagen para la Asistencia\n",
        "\n",
        "Ahora es el momento de pasar lista. En una aplicación real, esto implicaría capturar un fotograma en directo de una cámara web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iniciando cámara. Presiona 'q' para salir.\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 5: CAPTURAR VIDEO Y REALIZAR EL RECONOCIMIENTO FACIAL ---\n",
        "\n",
        "# Iniciar la captura de video desde la cámara web (el índice 0 suele ser la cámara por defecto).\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "print(\"\\nIniciando cámara. Presiona 'q' para salir.\")\n",
        "\n",
        "while True:\n",
        "    # Capturar un solo fotograma de video.\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "        print(\"Error: No se pudo capturar el fotograma.\")\n",
        "        break\n",
        "\n",
        "    # Redimensionar el fotograma para un procesamiento más rápido (opcional).\n",
        "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
        "\n",
        "    # Convertir la imagen de BGR (OpenCV) a RGB (face_recognition).\n",
        "    rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Encontrar todas las ubicaciones y codificaciones de rostros en el fotograma actual.\n",
        "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "\n",
        "    # Recorrer cada rostro encontrado en el fotograma.\n",
        "    for face_encoding, face_loc in zip(face_encodings, face_locations):\n",
        "        # Comparar el rostro actual con la lista de rostros conocidos.\n",
        "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "        name = \"Desconocido\"  # Nombre por defecto si no hay coincidencia.\n",
        "\n",
        "        # Encontrar la mejor coincidencia usando la distancia euclidiana.\n",
        "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "        best_match_index = np.argmin(face_distances)\n",
        "        \n",
        "        if matches[best_match_index]:\n",
        "            name = known_face_names[best_match_index]\n",
        "            # Llamar a la función para marcar la asistencia\n",
        "            mark_attendance(name)\n",
        "\n",
        "        # Dibujar un cuadro alrededor del rostro y mostrar el nombre.\n",
        "        # Escalar las ubicaciones del rostro al tamaño original del fotograma.\n",
        "        top, right, bottom, left = face_loc\n",
        "        top *= 4\n",
        "        right *= 4\n",
        "        bottom *= 4\n",
        "        left *= 4\n",
        "\n",
        "        # Dibujar el rectángulo y la etiqueta con el nombre.\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
        "        font = cv2.FONT_HERSHEY_DUPLEX\n",
        "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "\n",
        "    # Mostrar la imagen resultante.\n",
        "    cv2.imshow('Reconocimiento Facial - Asistencia (Presiona \"q\" para salir)', frame)\n",
        "\n",
        "    # Salir del bucle si se presiona la tecla 'q'.\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Liberar recursos al finalizar\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxEfnSo6aJV0"
      },
      "source": [
        "\n",
        "### Paso 6: Comprobar el registro de asistencia\n",
        "\n",
        "Por último, vamos a ver el contenido de nuestro archivo `attendance.csv`. Este archivo registra el nombre de la persona reconocida y la fecha y hora en que se marcó su asistencia. Cada persona sólo se marca una vez por sesión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Registro de Asistencia Final ---\n",
            "\n",
            "Adrian_DIAZ,2025-06-22 19:21:22\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 6: Comprobación de registros ---\n",
        "\n",
        "print(\"\\n--- Registro de Asistencia Final ---\")\n",
        "try:\n",
        "    with open('attendance.csv', 'r') as f:\n",
        "        print(f.read())\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo de asistencia no se creó. Nadie fue reconocido.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### POST DATA --- Procesando un video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Verificando la configuración inicial ---\n",
            "Directorio 'IMGV' encontrado. El programa continuará.\n",
            "Procesando rostros conocidos...\n",
            "Se procesaron 6 rostros.\n",
            "\n",
            "Procesando video: Best_of_Glambot_2025.mp4\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     97\u001b[39m rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m face_locations = \u001b[43mface_recognition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m face_encoding, face_loc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(face_encodings, face_locations):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FrijolitoRaza\\Documents\\Cursor\\FaceRecognition\\venv\\Lib\\site-packages\\face_recognition\\api.py:121\u001b[39m, in \u001b[36mface_locations\u001b[39m\u001b[34m(img, number_of_times_to_upsample, model)\u001b[39m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[33m\"\u001b[39m\u001b[33mcnn\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img.shape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FrijolitoRaza\\Documents\\Cursor\\FaceRecognition\\venv\\Lib\\site-packages\\face_recognition\\api.py:105\u001b[39m, in \u001b[36m_raw_face_locations\u001b[39m\u001b[34m(img, number_of_times_to_upsample, model)\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# Nombre del directorio para las imágenes de rostros conocidos.\n",
        "image_directory_name = \"IMGV\"\n",
        "image_path = Path(image_directory_name) # 1. Crear un objeto Path\n",
        "\n",
        "print(\"--- Verificando la configuración inicial ---\")\n",
        "\n",
        "# 2. Usar los métodos del objeto Path. Es más legible.\n",
        "if not image_path.is_dir(): \n",
        "    print(f\"El directorio '{image_path}' no fue encontrado.\")\n",
        "    \n",
        "    # 3. Crear el directorio. parents=True es para crear carpetas anidadas si fuera necesario.\n",
        "    image_path.mkdir(parents=True, exist_ok=True) \n",
        "    \n",
        "    # 4. Mensaje consolidado para el usuario.\n",
        "    print(f\"Se ha creado el directorio '{image_path}'.\\n\")\n",
        "    print(\"*\" * 25)\n",
        "    print(\"ACCIÓN REQUERIDA:\")\n",
        "    print(f\"Por favor, añade las imágenes de los rostros (.jpg, .png) en esta carpeta y vuelve a ejecutar el script.\")\n",
        "    print(\"*\" * 25)\n",
        "    \n",
        "    exit() # Se mantiene la lógica de salida, que es fundamental.\n",
        "else:\n",
        "    print(f\"Directorio '{image_path}' encontrado. El programa continuará.\")\n",
        "\n",
        "\n",
        "known_face_encodings = []\n",
        "known_face_names = []\n",
        "\n",
        "print(\"Procesando rostros conocidos...\")\n",
        "for filename in os.listdir(image_directory):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        image_path = os.path.join(image_directory, filename)\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "        face_encodings_list = face_recognition.face_encodings(image)\n",
        "        if face_encodings_list:\n",
        "            encoding = face_encodings_list[0]\n",
        "            known_face_encodings.append(encoding)\n",
        "            known_face_names.append(os.path.splitext(filename)[0])\n",
        "print(f\"Se procesaron {len(known_face_names)} rostros.\")\n",
        "\n",
        "# --- FUNCIÓN PARA MARCAR LA ASISTENCIA (Sin cambios) ---\n",
        "\n",
        "def mark_attendance(name):\n",
        "    with open('attendance_video.csv', 'a+') as f:\n",
        "        f.seek(0)\n",
        "        my_data_list = f.readlines()\n",
        "        name_list = [line.split(',')[0] for line in my_data_list]\n",
        "        if name not in name_list:\n",
        "            now = datetime.now()\n",
        "            dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "            f.writelines(f'\\n{name},{dt_string}')\n",
        "            print(f\"Rostro de {name} identificado y registrado.\")\n",
        "\n",
        "# --- PASO 2: PROCESAR EL VIDEO ---\n",
        "\n",
        "# --- PASO 3: PROCESAR TODOS LOS VIDEOS DE LA CARPETA 'video'\n",
        "video_folder = 'VideoIn'\n",
        "output_folder = 'VideoOut'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "video_files = [f for f in os.listdir(video_folder) if f.lower().endswith(('.mp4', '.avi', '.mov'))]\n",
        "\n",
        "for video_file in video_files:\n",
        "    input_video_path = os.path.join(video_folder, video_file)\n",
        "    output_video_path = os.path.join(output_folder, f'procesado_{video_file}')\n",
        "\n",
        "    video_capture = cv2.VideoCapture(input_video_path)\n",
        "    if not video_capture.isOpened():\n",
        "        print(f\"Error: No se pudo abrir el video {video_file}\")\n",
        "        continue\n",
        "\n",
        "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    print(f\"\\nProcesando video: {video_file}\")\n",
        "\n",
        "    while video_capture.isOpened():\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        face_locations = face_recognition.face_locations(rgb_frame)\n",
        "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
        "\n",
        "        for face_encoding, face_loc in zip(face_encodings, face_locations):\n",
        "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "            name = \"Desconocido\"\n",
        "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "            best_match_index = np.argmin(face_distances)\n",
        "            if matches[best_match_index]:\n",
        "                name = known_face_names[best_match_index]\n",
        "                mark_attendance(name)\n",
        "\n",
        "            top, right, bottom, left = face_loc\n",
        "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
        "            cv2.putText(frame, name, (left + 6, bottom - 6),\n",
        "                        cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
        "\n",
        "        video_writer.write(frame)\n",
        "\n",
        "    video_capture.release()\n",
        "    video_writer.release()\n",
        "    print(f\"✔ Video guardado: {output_video_path}\")\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "print(\"\\nTodos los videos fueron procesados correctamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Verificando la configuración inicial ---\n",
            "Directorio 'IMGV' encontrado. Continuando...\n",
            "\n",
            "Procesando rostros conocidos...\n",
            "✔ Se procesaron 6 rostros conocidos.\n",
            "\n",
            "Procesando video: Best_of_Glambot_2025.mp4\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     90\u001b[39m rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m face_locations = \u001b[43mface_recognition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m encodings = face_recognition.face_encodings(rgb, face_locations)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m encoding, loc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(encodings, face_locations):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FrijolitoRaza\\Documents\\Cursor\\FaceRecognition\\venv\\Lib\\site-packages\\face_recognition\\api.py:121\u001b[39m, in \u001b[36mface_locations\u001b[39m\u001b[34m(img, number_of_times_to_upsample, model)\u001b[39m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[33m\"\u001b[39m\u001b[33mcnn\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img.shape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FrijolitoRaza\\Documents\\Cursor\\FaceRecognition\\venv\\Lib\\site-packages\\face_recognition\\api.py:105\u001b[39m, in \u001b[36m_raw_face_locations\u001b[39m\u001b[34m(img, number_of_times_to_upsample, model)\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# --- CONFIGURACIÓN DE RUTAS ---\n",
        "image_path = Path(\"IMGV\")\n",
        "video_folder = Path(\"VideoIn\")\n",
        "output_folder = Path(\"VideoOut\")\n",
        "output_folder.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"--- Verificando la configuración inicial ---\")\n",
        "\n",
        "# --- CREAR DIRECTORIO PARA IMÁGENES SI NO EXISTE ---\n",
        "if not image_path.is_dir():\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"\\nSe ha creado la carpeta '{image_path}'.\")\n",
        "    print(\"*\" * 25)\n",
        "    print(\"ACCIÓN REQUERIDA:\")\n",
        "    print(\"Agrega imágenes (.jpg/.png) de rostros conocidos en esa carpeta.\")\n",
        "    print(\"*\" * 25)\n",
        "    exit()\n",
        "\n",
        "print(f\"Directorio '{image_path}' encontrado. Continuando...\\n\")\n",
        "\n",
        "# --- CARGAR ROSTROS CONOCIDOS ---\n",
        "known_face_encodings = []\n",
        "known_face_names = []\n",
        "\n",
        "print(\"Procesando rostros conocidos...\")\n",
        "\n",
        "for img_file in image_path.glob(\"*.[jp][pn]g\"):  # .jpg, .jpeg, .png\n",
        "    image = face_recognition.load_image_file(img_file)\n",
        "    encodings = face_recognition.face_encodings(image)\n",
        "    if encodings:\n",
        "        known_face_encodings.append(encodings[0])\n",
        "        known_face_names.append(img_file.stem)\n",
        "\n",
        "print(f\"✔ Se procesaron {len(known_face_names)} rostros conocidos.\")\n",
        "\n",
        "# --- FUNCION PARA REGISTRAR ASISTENCIA ---\n",
        "attendance_file = Path(\"attendance_video.csv\")\n",
        "attendance_set = set()\n",
        "\n",
        "if attendance_file.exists():\n",
        "    with attendance_file.open() as f:\n",
        "        reader = csv.reader(f)\n",
        "        attendance_set = {row[0] for row in reader if row}\n",
        "\n",
        "def mark_attendance(name):\n",
        "    if name not in attendance_set:\n",
        "        now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        with attendance_file.open(\"a\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([name, now])\n",
        "        attendance_set.add(name)\n",
        "        print(f\"✔ Rostro identificado: {name} (asistencia registrada)\")\n",
        "\n",
        "# --- PROCESAR VIDEOS ---\n",
        "video_files = [f for f in video_folder.glob(\"*\") if f.suffix.lower() in ['.mp4', '.avi', '.mov']]\n",
        "\n",
        "if not video_files:\n",
        "    print(\"⚠ No se encontraron videos en la carpeta VideoIn.\")\n",
        "    exit()\n",
        "\n",
        "for video_file in video_files:\n",
        "    print(f\"\\nProcesando video: {video_file.name}\")\n",
        "    cap = cv2.VideoCapture(str(video_file))\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"❌ No se pudo abrir: {video_file.name}\")\n",
        "        continue\n",
        "\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 24  # fallback a 24 fps\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "    output_path = output_folder / f\"procesado_{video_file.name}\"\n",
        "    out = cv2.VideoWriter(str(output_path), fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        face_locations = face_recognition.face_locations(rgb)\n",
        "        encodings = face_recognition.face_encodings(rgb, face_locations)\n",
        "\n",
        "        for encoding, loc in zip(encodings, face_locations):\n",
        "            matches = face_recognition.compare_faces(known_face_encodings, encoding)\n",
        "            name = \"Desconocido\"\n",
        "\n",
        "            if matches:\n",
        "                distances = face_recognition.face_distance(known_face_encodings, encoding)\n",
        "                best_match = np.argmin(distances)\n",
        "                if matches[best_match]:\n",
        "                    name = known_face_names[best_match]\n",
        "                    mark_attendance(name)\n",
        "\n",
        "            top, right, bottom, left = loc\n",
        "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
        "            cv2.putText(frame, name, (left + 6, bottom - 6),\n",
        "                        cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"✔ Video guardado como: {output_path.name}\")\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "print(\"\\n✅ Todos los videos fueron procesados exitosamente.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
