{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLVXlB5GaJVv"
      },
      "source": [
        "# Sistema de asistencia basado en el reconocimiento facial\n",
        "\n",
        "## Introducción\n",
        "\n",
        "Este proyecto muestra un Sistema de asistencia basado en el reconocimiento facial desarrollado en Python. Los sistemas tradicionales de control de asistencia suelen ser manuales, propensos a errores y lentos. Aprovechando el reconocimiento facial, podemos automatizar el proceso, creando una solución más eficiente, precisa y rentable. Esto es especialmente beneficioso para instituciones como escuelas y empresas, donde el control de asistencia de un gran número de personas es una tarea diaria. La automatización elimina los errores humanos, evita las entradas fraudulentas (como la asistencia por poder) y libera un tiempo valioso para actividades más productivas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFK-FPCNaJVx"
      },
      "source": [
        "## Antecedentes y motivación\n",
        "\n",
        "Los sistemas manuales de control de asistencia adolecen de varios inconvenientes, como la posibilidad de cometer errores, el posible robo de tiempo o falsificación de registros asistenciales, y la carga administrativa que supone compilar manualmente los registros. Grandes empresas tecnológicas como Amazon, Microsoft y Face++ ya han demostrado el poder del reconocimiento facial para la seguridad, el control de acceso y la identificación de usuarios.\n",
        "\n",
        "La motivación de este proyecto es aplicar conceptos fundamentales de la visión por ordenador y el aprendizaje automático para crear una aplicación práctica en el mundo real. El objetivo es crear un prototipo accesible y de bajo coste que pueda implementarse utilizando una cámara web estándar y bibliotecas Python de código abierto, convirtiéndolo en una opción viable para organizaciones con presupuestos limitados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajGf4NaRaJVx"
      },
      "source": [
        "## Desarrollo del proyecto\n",
        "\n",
        "### Herramientas utilizadas\n",
        "\n",
        "* Lenguaje de programación:Python\n",
        "* **Bibliotecas:**\n",
        "    * `NumPy`: Para operaciones numéricas y manejo de datos de imagen como matrices.\n",
        "    * `OpenCV`: Para procesamiento y manejo de imágenes.\n",
        "    * `face_recognition`: Una librería sencilla y potente para detectar, reconocer y manipular caras.\n",
        "    * `cmake`: Herramienta que configura y gestiona la compilación de bibliotecas como `dlib`.\n",
        "    * `dlib`: Biblioteca que proporciona algoritmos para la deteción y codificación de rostros, fundamentales para el reconocimiento facial.\n",
        "* **Hardware:** Ordenador portátil o de sobremesa con webcam (para captura de imágenes).\n",
        "* **Entorno de desarrollo:** Cursor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fePhv3JaJVx"
      },
      "source": [
        "### Paso 1: Instalar e importar las librerías necesarias\n",
        "\n",
        "En primer lugar, tenemos que instalar las bibliotecas necesarias. `dlib` es un prerrequisito para `face_recognition`. También instalaremos `cmake` para asegurarnos de que `dlib` compila correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adicionalmente, en caso de errores al tratar de instalar CMake, descargalo desde su sitio web oficial: https://cmake.org/download/. Abrí el instalador, marcá la opción \"Add CMake to system PATH for all users\", instalá, reiniciá la terminal y corré esta línea de código:\n",
        "\n",
        "\n",
        "`cmake --version`\n",
        "\n",
        "Deberías recibir un mensaje con la versión instalada de dicho sistema.\n",
        "\n",
        "Por otro lado, en caso de tener errores en la instalación de dlib, descargá Visual Studio 2022, en su versión Community, desde https://visualstudio.microsoft.com/es/downloads/. Luego, en el instalador, seleccioná \"Desarrollo para el escritorio con C++\" y continuá con la instalación. Finalmente, reiniciá la terminal e intentá instalar las dependencias nuevamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbhuJlR9aJVy",
        "outputId": "09793432-b593-4fee-fa3d-7b319044f32c"
      },
      "outputs": [],
      "source": [
        "!pip install requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVQjf4MAaJVy"
      },
      "source": [
        "Ahora, vamos a importar las bibliotecas que vamos a utilizar en todo el proyecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF-WBzSgaJVz"
      },
      "source": [
        "### Paso 2: Cargar imágenes de personas conocidas\n",
        "\n",
        "Necesitamos una base de datos de caras conocidas con las que comparar. Para este notebook, crearemos un directorio llamado `known_faces` y cargaremos imágenes en él. Cada archivo de imagen debe llevar el nombre de la persona que aparece en la foto (por ejemplo, `elon_musk.jpg`, `bill_gates.png`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- PASO 2: ENRUTADOR A LOS ROSTROS CONOCIDOS ---\n",
        "\n",
        "# Ruta al directorio con las imágenes de las personas conocidas.\n",
        "known_faces_dir = 'C:/Users/Ruta_local'\n",
        "\n",
        "### Reemplazar la ruta actual por la nueva ruta local\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0etenkzaJVz"
      },
      "source": [
        "### Paso 3: Codificar 'Known Faces'\n",
        "\n",
        "El núcleo del reconocimiento facial es convertir una cara en una representación matemática, llamada «codificación». Se trata de un vector de 128 números que es único para cada cara. Ahora procesaremos cada imagen cargada, detectaremos la cara y generaremos su codificación. Almacenaremos estas codificaciones junto con el nombre de la persona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando rostros conocidos...\n",
            "Se procesaron 6 rostros conocidos.\n",
            "Nombres conocidos: ['Adrian_DIAZ', 'Ana_DEARMAS', 'Daiana_FRETE', 'Hanna_DIAZ', 'Michael_MANDO', 'Nataly_PEREZ']\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 3: CODIFICAR LOS ROSTROS CONOCIDOS ---\n",
        "# \n",
        "# # Listas para almacenar las codificaciones de los rostros conocidos y sus nombres.\n",
        "known_face_encodings = []\n",
        "known_face_names = []\n",
        "\n",
        "print(\"Procesando rostros conocidos...\")\n",
        "\n",
        "# Recorrer cada archivo en el directorio de rostros conocidos.\n",
        "for filename in os.listdir(known_faces_dir):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        # Cargar el archivo de imagen.\n",
        "        image_path = os.path.join(known_faces_dir, filename)\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "\n",
        "        # Obtener la codificación del rostro (se asume una cara por imagen).\n",
        "        face_encodings = face_recognition.face_encodings(image)\n",
        "\n",
        "        if face_encodings:\n",
        "            encoding = face_encodings[0]\n",
        "            # Agregar la codificación y el nombre (sin la extensión del archivo) a las listas.\n",
        "            known_face_encodings.append(encoding)\n",
        "            known_face_names.append(os.path.splitext(filename)[0])\n",
        "\n",
        "print(f\"Se procesaron {len(known_face_names)} rostros conocidos.\")\n",
        "print(\"Nombres conocidos:\", known_face_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PASO 4: REGISTRAR LOS ROSTROS CONOCIDOS COMO ASISTENCIAS\n",
        "\n",
        "\n",
        "Se registra la asistencia de una persona en el archivo `attendance.csv`, guardando su nombre y la hora exacta en que fue detectada. Antes de agregar una nueva entrada, verifica si esa persona ya fue registrada en la sesión actual, evitando duplicados. Usa el modo de archivo 'a+' para permitir lectura y escritura, y para crear el archivo si no existe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- PASO 4: FUNCIÓN PARA MARCAR LA ASISTENCIA ---\n",
        "\n",
        "def mark_attendance(name):\n",
        "    \"\"\"\n",
        "    Registra el nombre y la hora en el archivo attendance.csv.\n",
        "    Evita registrar a la misma persona más de una vez por sesión.\n",
        "    \"\"\"\n",
        "    # Usar 'a+' para abrir el archivo en modo de anexo (lo crea si no existe).\n",
        "    with open('attendance.csv', 'a+') as f:\n",
        "        # Mover el cursor al inicio para leer las entradas existentes.\n",
        "        f.seek(0)\n",
        "        my_data_list = f.readlines()\n",
        "        name_list = []\n",
        "        for line in my_data_list:\n",
        "            entry = line.split(',')\n",
        "            name_list.append(entry[0])\n",
        "\n",
        "        # Comprobar si el nombre no ha sido ya registrado.\n",
        "        if name not in name_list:\n",
        "            now = datetime.now()\n",
        "            dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "            f.writelines(f'\\n{name},{dt_string}')\n",
        "            print(f\"Asistencia marcada para {name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNKiyM5UaJV0"
      },
      "source": [
        "### Paso 5: Capturar una Imagen para la Asistencia\n",
        "\n",
        "Ahora es el momento de pasar lista. En una aplicación real, esto implicaría capturar un fotograma en directo de una cámara web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iniciando cámara. Presiona 'q' para salir.\n",
            "Asistencia marcada para Adrian_DIAZ\n",
            "Asistencia marcada para Daiana_FRETE\n",
            "Asistencia marcada para Hanna_DIAZ\n",
            "Asistencia marcada para Nataly_PEREZ\n",
            "Asistencia marcada para Ana_DEARMAS\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# --- PASO 5: CAPTURAR VIDEO Y REALIZAR EL RECONOCIMIENTO FACIAL ---\n",
        "\n",
        "# Iniciar la captura de video desde la cámara web (el índice 0 suele ser la cámara por defecto).\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "print(\"\\nIniciando cámara. Presiona 'q' para salir.\")\n",
        "\n",
        "while True:\n",
        "    # Capturar un solo fotograma de video.\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "        print(\"Error: No se pudo capturar el fotograma.\")\n",
        "        break\n",
        "\n",
        "    # Redimensionar el fotograma para un procesamiento más rápido (opcional).\n",
        "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
        "\n",
        "    # Convertir la imagen de BGR (OpenCV) a RGB (face_recognition).\n",
        "    rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Encontrar todas las ubicaciones y codificaciones de rostros en el fotograma actual.\n",
        "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "\n",
        "    # Recorrer cada rostro encontrado en el fotograma.\n",
        "    for face_encoding, face_loc in zip(face_encodings, face_locations):\n",
        "        # Comparar el rostro actual con la lista de rostros conocidos.\n",
        "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "        name = \"Desconocido\"  # Nombre por defecto si no hay coincidencia.\n",
        "\n",
        "        # Encontrar la mejor coincidencia usando la distancia euclidiana.\n",
        "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "        best_match_index = np.argmin(face_distances)\n",
        "        \n",
        "        if matches[best_match_index]:\n",
        "            name = known_face_names[best_match_index]\n",
        "            mark_attendance(name)\n",
        "\n",
        "        # Dibujar un cuadro alrededor del rostro y mostrar el nombre.\n",
        "        # Escalar las ubicaciones del rostro al tamaño original del fotograma.\n",
        "        top, right, bottom, left = face_loc\n",
        "        top *= 4\n",
        "        right *= 4\n",
        "        bottom *= 4\n",
        "        left *= 4\n",
        "\n",
        "        # Dibujar el rectángulo y la etiqueta con el nombre.\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
        "        font = cv2.FONT_HERSHEY_DUPLEX\n",
        "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "\n",
        "    # Mostrar la imagen resultante.\n",
        "    cv2.imshow('Reconocimiento Facial - Asistencia (Presiona \"q\" para salir)', frame)\n",
        "\n",
        "    # Salir del bucle si se presiona la tecla 'q'.\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmLAOpoGaJV0"
      },
      "source": [
        "### Paso 6: Comparar las caras capturadas y marcar la asistencia\n",
        "\n",
        "Este es el paso final. Haremos lo siguiente\n",
        "1.  Cargar la imagen de asistencia cargada.\n",
        "2.  Encontrar todas las caras y sus codificaciones en esta imagen.\n",
        "3.  Comparar cada cara encontrada con nuestra base de datos de codificaciones de caras conocidas.\n",
        "4.  Si se encuentra una coincidencia, identificaremos a la persona.\n",
        "5.  Dibujar un recuadro alrededor de la cara y etiquetarlo con el nombre.\n",
        "6.  Registrar la asistencia en un fichero CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F24Sl_NHaJV0"
      },
      "outputs": [],
      "source": [
        "# Function to mark attendance\n",
        "def mark_attendance(name):\n",
        "    # Use 'a+' to create the file if it doesn't exist and append to it\n",
        "    with open('attendance.csv', 'a+') as f:\n",
        "        # Move cursor to the start to read existing entries\n",
        "        f.seek(0)\n",
        "        my_data_list = f.readlines()\n",
        "        name_list = []\n",
        "        for line in my_data_list:\n",
        "            entry = line.split(',')\n",
        "            name_list.append(entry[0])\n",
        "\n",
        "        # Check if the name is not already in the list for today\n",
        "        if name not in name_list:\n",
        "            now = datetime.now()\n",
        "            dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "            f.writelines(f'\\n{name},{dt_string}')\n",
        "            print(f\"Attendance marked for {name}\")\n",
        "\n",
        "# Load the attendance image\n",
        "img = cv2.imread(attendance_image_name)\n",
        "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Find face locations and encodings in the current frame\n",
        "face_locations = face_recognition.face_locations(rgb_img)\n",
        "face_encodings = face_recognition.face_encodings(rgb_img, face_locations)\n",
        "\n",
        "print(f\"Found {len(face_locations)} face(s) in the attendance image.\")\n",
        "\n",
        "# Loop through each face found in the attendance image\n",
        "for face_encoding, face_loc in zip(face_encodings, face_locations):\n",
        "    # See if the face is a match for the known face(s)\n",
        "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "    name = \"Unknown\" # Default name if no match is found\n",
        "\n",
        "    # Use the known face with the smallest distance to the new face\n",
        "    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "    best_match_index = np.argmin(face_distances)\n",
        "    if matches[best_match_index]:\n",
        "        name = known_face_names[best_match_index]\n",
        "        mark_attendance(name)\n",
        "\n",
        "    # Draw a box around the face and display the name\n",
        "    top, right, bottom, left = face_loc\n",
        "    cv2.rectangle(img, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "    cv2.rectangle(img, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
        "    font = cv2.FONT_HERSHEY_DUPLEX\n",
        "    cv2.putText(img, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "\n",
        "# Display the resulting image\n",
        "print(\"\\nDisplaying result:\")\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxEfnSo6aJV0"
      },
      "source": [
        "\n",
        "### Paso 7: Comprobar el registro de asistencia\n",
        "\n",
        "Por último, vamos a ver el contenido de nuestro archivo `attendance.csv`. Este archivo registra el nombre de la persona reconocida y la fecha y hora en que se marcó su asistencia. Cada persona sólo se marca una vez por sesión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- PASO 7: LIBERAR RECURSOS ---\n",
        "\n",
        "# Liberar el manejador de la cámara web.\n",
        "video_capture.release()\n",
        "# Cerrar todas las ventanas de OpenCV.\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"\\n--- Registro de Asistencia Final ---\")\n",
        "try:\n",
        "    with open('attendance.csv', 'r') as f:\n",
        "        print(f.read())\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo de asistencia no se creó. Nadie fue reconocido.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
